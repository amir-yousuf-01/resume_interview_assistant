# -*- coding: utf-8 -*-
"""resume_interview_assistant

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1V-7tOCWl9oq7vc89mZpbI0fD8Q3Hsbg4

## Step 1: **Install Required Packages**
"""

!pip install groq

"""## Step 2: **Import Libraries**"""

import json
from groq import Groq

"""##Step 3: **Mount Google Drive**"""

from google.colab import drive
drive.mount('/content/drive')

"""## Step 3: **Load API Key from Google Drive**"""

with open("/content/drive/MyDrive/api-key.txt", "r") as f:
    API_KEY = f.read().strip()

print("API key loaded successfully!")

"""  ## Step 5: **Create InterviewCoach Class**"""

# Continue from your existing code...
print("API key loaded successfully!")

# Initialize Groq client
client = Groq(api_key=API_KEY)

class InterviewCoach:
    """
    Interview Coach using Groq API - Updated with current models
    """

    def __init__(self, groq_client):
        self.client = groq_client
        # CURRENT AVAILABLE MODELS (as of Dec 2024)
        self.available_models = {
            "fast": "llama-3.1-8b-instant",      # Fastest
            "balanced": "mixtral-8x7b-32768",    # Best balance
            "quality": "llama-3.2-90b-text-preview", # Highest quality
        }

    def analyze_resume_job_fit(self, resume_text, job_description):
        """Analyze resume vs job description using Groq"""

        prompt = f"""
        ACT as a professional career coach and HR expert. Analyze the resume against the job description and provide a comprehensive analysis.

        RESUME:
        {resume_text}

        JOB DESCRIPTION:
        {job_description}

        Provide analysis in this EXACT JSON format:
        {{
            "match_score": 85,
            "skills_present": ["Python", "Machine Learning", "Data Analysis"],
            "skills_missing": ["TensorFlow", "AWS", "Docker"],
            "strengths": ["Strong technical background", "Relevant project experience"],
            "weaknesses": ["Lacks cloud experience", "No mention of specific tools"],
            "resume_improvements": [
                {{
                    "category": "Quantifiable Achievements",
                    "suggestion": "Add metrics to your achievements",
                    "reason": "Makes impact more measurable"
                }}
            ],
            "interview_questions": [
                {{
                    "question": "Describe your experience with Python",
                    "rationale": "Key skill mentioned in job description",
                    "key_points": "Projects, libraries used, results achieved",
                    "difficulty": "Medium",
                    "question_type": "technical"
                }}
            ],
            "salary_estimate": {{
                "range": "$80,000 - $100,000",
                "confidence": "High",
                "factors": ["Experience level", "Skills match", "Industry standards"]
            }}
        }}

        Be realistic and critical in your analysis. Focus on actionable insights.
        """

        try:
            chat_completion = self.client.chat.completions.create(
                messages=[
                    {
                        "role": "system",
                        "content": "You are an expert career coach and HR professional with 15 years of experience. Always return valid JSON."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                model=self.available_models["balanced"],  # Use mixtral-8x7b-32768
                temperature=0.3,
                max_tokens=4000,
                response_format={"type": "json_object"}
            )

            response = chat_completion.choices[0].message.content
            print(" API call successful!")
            return json.loads(response.strip())

        except Exception as e:
            print(f"Error in Groq API call: {e}")
            # Try fallback model
            return self._try_fallback_model(prompt, "analyze")

    def generate_interview_questions(self, resume_text, job_description, question_type="mixed", count=5):
        """Generate specific interview questions using Groq"""

        prompt = f"""
        Based on the resume and job description, generate {count} {question_type} interview questions.

        RESUME:
        {resume_text}

        JOB DESCRIPTION:
        {job_description}

        QUESTION TYPE: {question_type}

        Return in this JSON format:
        {{
            "questions": [
                {{
                    "question": "Question text here",
                    "type": "technical/behavioral/situational",
                    "rationale": "Why this question is relevant",
                    "expected_keywords": ["keyword1", "keyword2"],
                    "difficulty": "Easy/Medium/Hard"
                }}
            ]
        }}
        """

        try:
            chat_completion = self.client.chat.completions.create(
                messages=[{"role": "user", "content": prompt}],
                model=self.available_models["fast"],  # Use llama-3.1-8b-instant for speed
                temperature=0.7,
                max_tokens=2000,
                response_format={"type": "json_object"}
            )

            response = chat_completion.choices[0].message.content
            print(" Questions generated successfully!")
            return json.loads(response.strip())

        except Exception as e:
            print(f"Error generating questions: {e}")
            # Try fallback model
            return self._try_fallback_model(prompt, "questions")

    def evaluate_answer(self, question, user_answer, context):
        """Evaluate user's interview answer using Groq"""

        prompt = f"""
        Evaluate this interview answer professionally:

        QUESTION: {question}
        USER'S ANSWER: {user_answer}
        CONTEXT: {context}

        Provide evaluation in this JSON format:
        {{
            "score": 7,
            "score_explanation": "Explanation of scoring",
            "strengths": ["Good structure", "Relevant examples"],
            "improvements": ["Add more specifics", "Use STAR method"],
            "detailed_feedback": "Comprehensive feedback here",
            "suggested_better_answer": "How to improve the answer"
        }}

        Be constructive but honest in your evaluation.
        """

        try:
            chat_completion = self.client.chat.completions.create(
                messages=[{"role": "user", "content": prompt}],
                model=self.available_models["balanced"],  # Use mixtral-8x7b-32768
                temperature=0.4,
                max_tokens=1500,
                response_format={"type": "json_object"}
            )

            response = chat_completion.choices[0].message.content
            print(" Answer evaluated successfully!")
            return json.loads(response.strip())

        except Exception as e:
            print(f"Error evaluating answer: {e}")
            # Try fallback model
            return self._try_fallback_model(prompt, "evaluate")

    def _try_fallback_model(self, prompt, task_type):
        """Try fallback models if primary fails"""
        fallback_models = ["llama-3.1-8b-instant", "mixtral-8x7b-32768"]

        for model in fallback_models:
            try:
                print(f" Trying fallback model: {model}")
                chat_completion = self.client.chat.completions.create(
                    messages=[{"role": "user", "content": prompt}],
                    model=model,
                    temperature=0.3,
                    max_tokens=4000,
                    response_format={"type": "json_object"}
                )

                response = chat_completion.choices[0].message.content
                print(f" Success with fallback model: {model}")
                return json.loads(response.strip())

            except Exception as e:
                print(f" Fallback model {model} also failed: {e}")
                continue

        # If all models fail, return demo data
        print("ðŸŽ­ All models failed, using demo data")
        if task_type == "analyze":
            return self.get_fallback_analysis()
        elif task_type == "questions":
            return {"questions": self.get_fallback_questions()}
        else:
            return self.get_fallback_evaluation()

    def get_current_models(self):
        """Get list of currently available models"""
        try:
            # This would require Groq to have a models endpoint
            # For now, return our hardcoded available models
            return list(self.available_models.values())
        except:
            return ["llama-3.1-8b-instant", "mixtral-8x7b-32768"]

    def get_fallback_analysis(self):
        """Fallback analysis if API fails"""
        return {
            "match_score": 78,
            "skills_present": ["Python", "Machine Learning", "Data Analysis", "SQL", "Pandas", "Scikit-learn"],
            "skills_missing": ["TensorFlow", "AWS", "Docker", "Kubernetes", "Big Data"],
            "strengths": ["Strong technical foundation", "Relevant project experience", "Good problem-solving skills"],
            "weaknesses": ["Limited cloud experience", "No containerization tools", "Missing specific ML frameworks"],
            "resume_improvements": [
                {
                    "category": "Quantifiable Achievements",
                    "suggestion": "Add specific metrics like 'improved model accuracy by 25%' or 'reduced processing time by 30%'",
                    "reason": "Quantifiable results are more impactful to recruiters"
                },
                {
                    "category": "Keyword Optimization",
                    "suggestion": "Include more keywords from the job description like 'machine learning', 'data pipeline', 'cloud computing'",
                    "reason": "Many companies use ATS systems that scan for specific keywords"
                },
                {
                    "category": "Action Verbs",
                    "suggestion": "Start bullet points with stronger action verbs: 'Spearheaded', 'Engineered', 'Optimized' instead of 'Responsible for'",
                    "reason": "Stronger verbs demonstrate proactivity and impact"
                }
            ],
            "interview_questions": [
                {
                    "question": "Can you describe your experience with machine learning projects?",
                    "rationale": "ML is a key requirement in the job description",
                    "key_points": "Specific projects, algorithms used, results achieved, tools/libraries",
                    "difficulty": "Hard",
                    "question_type": "technical"
                },
                {
                    "question": "How do you handle tight deadlines in project management?",
                    "rationale": "Tests your time management and pressure handling",
                    "key_points": "Prioritization methods, communication strategies, example scenarios",
                    "difficulty": "Medium",
                    "question_type": "behavioral"
                },
                {
                    "question": "What's your approach to learning new technologies?",
                    "rationale": "Assesses adaptability and continuous learning mindset",
                    "key_points": "Learning methods, recent skills learned, application in projects",
                    "difficulty": "Easy",
                    "question_type": "behavioral"
                }
            ],
            "salary_estimate": {
                "range": "$85,000 - $110,000",
                "confidence": "High",
                "factors": ["3 years experience", "Strong technical skills", "High demand field"]
            }
        }

    def get_fallback_questions(self):
        """Fallback questions if API fails"""
        return [
                {
                    "question": "Describe your most challenging data science project and how you approached it",
                    "type": "technical",
                    "rationale": "Tests problem-solving and technical depth",
                    "expected_keywords": ["challenges", "solutions", "results", "methodology"],
                    "difficulty": "Hard"
                },
                {
                    "question": "How do you collaborate with non-technical stakeholders?",
                    "type": "behavioral",
                    "rationale": "Assesses communication and teamwork skills",
                    "expected_keywords": ["communication", "collaboration", "examples", "adaptation"],
                    "difficulty": "Medium"
                },
                {
                    "question": "Where do you see yourself in 5 years?",
                    "type": "motivational",
                    "rationale": "Evaluates career goals and alignment with company",
                    "expected_keywords": ["growth", "learning", "contribution", "alignment"],
                    "difficulty": "Easy"
                }
            ]

    def get_fallback_evaluation(self):
        """Fallback evaluation if API fails"""
        return {
            "score": 7,
            "score_explanation": "Good answer with clear structure but needs more specific examples",
            "strengths": ["Relevant to question", "Good communication", "Shows enthusiasm"],
            "improvements": ["Add quantifiable results", "Use STAR method structure", "Include more technical details"],
            "detailed_feedback": "Your answer addresses the question well and shows good communication skills. However, it would be stronger with specific, quantifiable examples and a more structured approach using the STAR method.",
            "suggested_better_answer": "In my previous role at XYZ Company (Situation), I was tasked with improving our data processing pipeline (Task). I implemented a new machine learning algorithm using Python and Scikit-learn (Action), which reduced processing time by 40% and improved accuracy by 15% (Result)."
        }

# Create the interview coach instance
print(" Initializing Interview Coach...")
interview_coach = InterviewCoach(client)

# Display available models
print(f" Available Models: {interview_coach.get_current_models()}")
print(" Interview Coach initialized successfully!")

# Test with sample data
print("\n Testing with sample data...")

test_resume = """
John Doe - Senior Data Scientist
Email: john.doe@email.com | Phone: (555) 123-4567

PROFESSIONAL EXPERIENCE:
Senior Data Scientist, Tech Company Inc. (2020-Present)
- Developed machine learning models that improved prediction accuracy by 25%
- Led a team of 3 junior data scientists on customer segmentation projects
- Implemented data pipelines processing 1TB+ of data daily using Python and SQL
- Reduced model training time by 40% through optimization techniques

Data Analyst, Startup Co. (2018-2020)
- Created dashboards and reports that informed business strategy
- Analyzed customer behavior data to identify growth opportunities
- Collaborated with marketing team to optimize campaigns

TECHNICAL SKILLS:
Programming: Python, SQL, R, Java
Machine Learning: Scikit-learn, TensorFlow, PyTorch, XGBoost
Data Tools: Pandas, NumPy, Matplotlib, Tableau
Cloud: AWS (S3, EC2), Google Cloud Platform

EDUCATION:
MS in Computer Science, University of Technology (2018)
BS in Statistics, State University (2016)

CERTIFICATIONS:
AWS Certified Machine Learning Specialist
Google Data Analytics Professional Certificate
"""

test_job = """
Senior Machine Learning Engineer

Job Description:
We are looking for a Senior Machine Learning Engineer to join our AI team.
You will be responsible for designing, building, and deploying machine learning models at scale.

Responsibilities:
- Design and implement machine learning models for production systems
- Develop and maintain data pipelines for model training and inference
- Collaborate with data scientists and software engineers to deploy models
- Optimize model performance and scalability
- Implement MLOps practices for model monitoring and retraining

Requirements:
- 5+ years of experience in machine learning or data science
- Strong proficiency in Python and machine learning frameworks (TensorFlow, PyTorch)
- Experience with cloud platforms (AWS, GCP, or Azure)
- Knowledge of MLOps tools and practices
- Experience with containerization (Docker, Kubernetes)
- Strong understanding of software engineering principles

Preferred Qualifications:
- Experience with big data technologies (Spark, Hadoop)
- Knowledge of deep learning architectures
- Experience with real-time inference systems
- Master's or PhD in Computer Science or related field
"""

# Test the analysis
print(" Testing resume analysis...")
analysis = interview_coach.analyze_resume_job_fit(test_resume, test_job)

print(f" Analysis completed!")
print(f"Match Score: {analysis.get('match_score', 0)}%")
print(f"Skills Found: {len(analysis.get('skills_present', []))}")
print(f"Skills Missing: {len(analysis.get('skills_missing', []))}")

print(f"\n Strengths:")
for strength in analysis.get('strengths', [])[:3]:
    print(f"   {strength}")

print(f"\n Areas for Improvement:")
for weakness in analysis.get('weaknesses', [])[:3]:
    print(f"   {weakness}")

print(f"\n Resume Improvements:")
for imp in analysis.get('resume_improvements', [])[:2]:
    print(f"   {imp.get('category')}: {imp.get('suggestion')}")

print(f"\n Interview Questions:")
for i, question in enumerate(analysis.get('interview_questions', [])[:3], 1):
    print(f"  {i}. {question.get('question')}")

print(f"\n Salary Estimate: {analysis.get('salary_estimate', {}).get('range', 'N/A')}")

# Test question generation
print("\n Testing question generation...")
questions = interview_coach.generate_interview_questions(test_resume, test_job, count=3)
print(f"Generated {len(questions.get('questions', []))} questions")

if questions.get('questions'):
    for i, q in enumerate(questions['questions'][:2], 1):
        print(f"  {i}. {q.get('question')}")

# Test answer evaluation
print("\n Testing answer evaluation...")
sample_question = "Describe your experience with machine learning projects"
sample_answer = "I have worked on several ML projects where I used Python and scikit-learn to build predictive models. I also have experience with data preprocessing and model deployment."

evaluation = interview_coach.evaluate_answer(sample_question, sample_answer, test_resume)
print(f"Answer Score: {evaluation.get('score', 0)}/10")
print(f"Strengths: {', '.join(evaluation.get('strengths', []))}")
print(f"Improvements: {', '.join(evaluation.get('improvements', []))}")

print("\n ALL TESTS COMPLETED SUCCESSFULLY!")
print(" Your Interview Coach is ready to use!")